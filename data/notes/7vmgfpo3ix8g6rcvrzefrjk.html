<h1 id="cvpr-2023vmap">(CVPR 2023)vMap<a aria-hidden="true" class="anchor-heading icon-link" href="#cvpr-2023vmap"></a></h1>
<p>做多个物体级别的实时重建任务。最多可以同时重建50个物体（MLP），5Hz的地图实时更新。</p>
<p><img src="/pub-notes/assets/doctor/vMAP_fig2.png" alt="系统架构" style=""></p>
<h2 id="创新点">创新点<a aria-hidden="true" class="anchor-heading icon-link" href="#创新点"></a></h2>
<ol>
<li>对场景的划分不同。DeRF将空间划分为较小的部分，然后使用小网络表示分解后的部分。KiloNeRF将空间划分为Volume,然后使用极小的MLP表示Volume元素，该方式可以加快nerf的训练。vMAP按物体级别的语义划分。</li>
<li><strong>多物体</strong> <strong>实时</strong>重建。</li>
</ol>
<h2 id="方法">方法<a aria-hidden="true" class="anchor-heading icon-link" href="#方法"></a></h2>
<p><strong>细节</strong></p>
<ol>
<li>RGBD物体掩码通过off-the-shelf分割网络预测，通过语义和空间一致性关联。</li>
<li>相机Tracking通过off-the-shelf追踪系统得到，比同时优化相机和几何效果好。</li>
<li>每一个物体都有自己的关键帧队列，不同物体之间的训练不会受到影响。</li>
<li>所有物体使用相同的网络，背景使用稍大的网络。网络可以stack
之后，做向量化并行化训练。</li>
<li>光线采样。高斯分布采样+均匀采样。</li>
<li>网络输入忽略视角的影响。使用二值函数建模物体的可见性（假设没有透明物体）。</li>
</ol>
<p><strong>Loss</strong></p>
<h2 id="实现">实现<a aria-hidden="true" class="anchor-heading icon-link" href="#实现"></a></h2>
<p><strong>设备</strong> RTX 3090 GPU， 3.60 GHz i7-11700K CPU</p>
<p><strong>框架选择</strong></p>
<ol>
<li>相机位姿通过orb-slam3得到。关键帧位姿通过orb-slam3连续更新。</li>
<li>分割网络使用Detic。在LVIS上预训练，包含1000个物体类别。</li>
</ol>
<p><strong>超参数</strong> </p>